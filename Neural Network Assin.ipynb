{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b84cb07-067e-443a-9599-607909edb72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Index(['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar',\n",
      "       'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge', 'xedgey',\n",
      "       'yedge', 'yedgex'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "               xbox          ybox         width       height         onpix  \\\n",
      "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
      "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
      "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
      "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
      "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
      "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
      "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
      "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
      "\n",
      "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
      "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
      "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
      "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
      "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
      "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
      "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
      "\n",
      "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
      "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
      "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
      "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
      "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
      "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
      "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
      "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
      "\n",
      "            yedgex  \n",
      "count  20000.00000  \n",
      "mean       7.80120  \n",
      "std        1.61747  \n",
      "min        0.00000  \n",
      "25%        7.00000  \n",
      "50%        8.00000  \n",
      "75%        9.00000  \n",
      "max       15.00000  \n",
      "letter\n",
      "U    813\n",
      "D    805\n",
      "P    803\n",
      "T    796\n",
      "M    792\n",
      "A    789\n",
      "X    787\n",
      "Y    786\n",
      "N    783\n",
      "Q    783\n",
      "F    775\n",
      "G    773\n",
      "E    768\n",
      "B    766\n",
      "V    764\n",
      "L    761\n",
      "R    758\n",
      "I    755\n",
      "O    753\n",
      "W    752\n",
      "S    748\n",
      "J    747\n",
      "K    739\n",
      "C    736\n",
      "H    734\n",
      "Z    734\n",
      "Name: count, dtype: int64\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step\n",
      "Optimizer: adam, Activation: relu, Neurons: 32, Accuracy: 0.8755\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Optimizer: adam, Activation: relu, Neurons: 64, Accuracy: 0.9225\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step\n",
      "Optimizer: adam, Activation: tanh, Neurons: 32, Accuracy: 0.88125\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step\n",
      "Optimizer: adam, Activation: tanh, Neurons: 64, Accuracy: 0.92275\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step\n",
      "Optimizer: sgd, Activation: relu, Neurons: 32, Accuracy: 0.7925\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step\n",
      "Optimizer: sgd, Activation: relu, Neurons: 64, Accuracy: 0.83225\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Optimizer: sgd, Activation: tanh, Neurons: 32, Accuracy: 0.7695\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Optimizer: sgd, Activation: tanh, Neurons: 64, Accuracy: 0.8145\n",
      "Best Hyperparameters: {'optimizer': 'adam', 'activation': 'tanh', 'neurons': 64}\n",
      "Best Accuracy: 0.92275\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       149\n",
      "           1       0.85      0.93      0.89       153\n",
      "           2       0.94      0.89      0.91       137\n",
      "           3       0.82      0.96      0.89       156\n",
      "           4       0.91      0.91      0.91       141\n",
      "           5       0.85      0.94      0.89       140\n",
      "           6       0.87      0.91      0.89       160\n",
      "           7       0.94      0.78      0.86       144\n",
      "           8       0.98      0.90      0.94       146\n",
      "           9       0.95      0.93      0.94       149\n",
      "          10       0.89      0.85      0.87       130\n",
      "          11       0.97      0.94      0.95       155\n",
      "          12       0.95      0.97      0.96       168\n",
      "          13       0.95      0.90      0.93       151\n",
      "          14       0.88      0.92      0.90       145\n",
      "          15       0.96      0.90      0.93       173\n",
      "          16       0.96      0.90      0.93       166\n",
      "          17       0.84      0.86      0.85       160\n",
      "          18       0.91      0.92      0.92       171\n",
      "          19       0.94      0.94      0.94       163\n",
      "          20       0.93      0.94      0.93       183\n",
      "          21       0.93      0.94      0.93       158\n",
      "          22       0.96      0.97      0.96       148\n",
      "          23       0.94      0.96      0.95       154\n",
      "          24       0.96      0.92      0.94       168\n",
      "          25       0.93      0.89      0.91       132\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n",
      "Final Model Accuracy: 0.91725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('Alphabets_data.csv')\n",
    "\n",
    "# Check the column names\n",
    "print(\"Column names in the dataset:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Data exploration\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Assuming 'letter' is the target variable\n",
    "target_column = 'letter'\n",
    "print(data[target_column].value_counts())  # Show the distribution of target classes\n",
    "\n",
    "# Preprocessing\n",
    "# Handle missing values by dropping rows with any missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[target_column])  # Drop the target label\n",
    "y = data[target_column]  # Keep the target label\n",
    "\n",
    "# Encode target labels if they are categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a basic ANN model function\n",
    "def build_ann_model(optimizer='adam', activation='relu', neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)) )  # Use Input layer for shape\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(len(np.unique(y_encoded)), activation='softmax'))  # Output layer\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# List of hyperparameters for manual tuning\n",
    "optimizers = ['adam', 'sgd']\n",
    "activations = ['relu', 'tanh']\n",
    "neurons_list = [32, 64]\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Manual Hyperparameter Tuning\n",
    "for optimizer in optimizers:\n",
    "    for activation in activations:\n",
    "        for neurons in neurons_list:\n",
    "            # Build and train the model\n",
    "            model = build_ann_model(optimizer=optimizer, activation=activation, neurons=neurons)\n",
    "            model.fit(X_train, y_train, epochs=10, batch_size=20, verbose=0)\n",
    "            \n",
    "            # Evaluate the model\n",
    "            y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"Optimizer: {optimizer}, Activation: {activation}, Neurons: {neurons}, Accuracy: {accuracy}\")\n",
    "            \n",
    "            # Save the best performing model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'optimizer': optimizer, 'activation': activation, 'neurons': neurons}\n",
    "\n",
    "# Output the best results\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = build_ann_model(**best_params)\n",
    "best_model.fit(X_train, y_train, epochs=10, batch_size=20, verbose=0)\n",
    "y_pred = np.argmax(best_model.predict(X_test), axis=-1)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Final Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433359c-15d2-4533-a0db-8e58447bb871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
